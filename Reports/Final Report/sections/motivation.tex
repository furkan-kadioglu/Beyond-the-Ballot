\begin{abstract}
    With the advent of ChatGPT, interdisciplinary studies on how large language models (LLMs) can be utilized have emerged. Questions such as whether survey participants could be replaced by LLMs, leveraging their human-like response generation, gained popularity. Alongside this, studies aimed at enhancing existing surveys using LLMs before considering participant replacement were also introduced. In this study, we explored whether it is possible to predict responses to questions not asked in a survey using the answers given to asked questions. To achieve this, we employed LLM and embeddings, another component of the transformer architecture that underpins LLM technologies. Discussions about LLMs being biased and functioning as black-box systems led us to integrate LLMs as part of a pipeline where their input and output could be transparently observed, rather than solely relying on LLMs to solve the problem. All the results obtained from the experiments and the related codebase are shared as open-source.\footnote{\url{https://github.com/furkan-kadioglu/Beyond-the-Ballot}}
\end{abstract}
